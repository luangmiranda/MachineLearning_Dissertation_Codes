{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9b12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 18:15:01.286539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-09 18:15:01.286589: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score)\n",
    "#import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "#import seaborn as sns\n",
    "#from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn_som.som import SOM\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "#import sys\n",
    "#np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f784dda",
   "metadata": {},
   "source": [
    "# Dados NSL-KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe194606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega dados do dataset\n",
    "#monday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Monday-WorkingHours.csv\", skipinitialspace = True)\n",
    "#tuesday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Tuesday-WorkingHours.csv\", skipinitialspace = True)\n",
    "#wednesday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Wednesday-WorkingHours.csv\", skipinitialspace = True)\n",
    "#thursday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Thursday-WorkingHours.csv\", skipinitialspace = True)\n",
    "#friday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Friday-WorkingHours.csv\", skipinitialspace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba076b14",
   "metadata": {},
   "source": [
    "# Carregamento Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4f84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega dados do dataset\n",
    "monday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Monday-WorkingHours.csv\", skipinitialspace = True)\n",
    "tuesday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Tuesday-WorkingHours.csv\", skipinitialspace = True)\n",
    "x = pd.concat((monday, tuesday), axis=0)\n",
    "del monday, tuesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf64cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wednesday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Wednesday-WorkingHours.csv\", skipinitialspace = True)\n",
    "x = pd.concat((x, wednesday), axis=0)\n",
    "del wednesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a35ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thursday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Thursday-WorkingHours.csv\", skipinitialspace = True)\n",
    "x = pd.concat((x, thursday), axis=0)\n",
    "del thursday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f991d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "friday = pd.read_csv(r\"CIC-IDS2017 ATUALIZADO/Friday-WorkingHours.csv\", skipinitialspace = True)\n",
    "x = pd.concat((x, friday), axis=0)\n",
    "del friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77402ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatena todos os datasets carregados\n",
    "#x = pd.concat((monday, tuesday, wednesday, thursday, friday), axis=0)\n",
    "x = x.drop(['Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Dst Port', 'Timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105be04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma o dataset multiclasse para binário\n",
    "x['Label'] = x['Label'].replace('BENIGN', 0)\n",
    "x['Label'] = x['Label'].replace('FTP-Patator', 1)\n",
    "x['Label'] = x['Label'].replace('SSH-Patator', 1)\n",
    "x['Label'] = x['Label'].replace('FTP-Patator - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('SSH-Patator - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('DoS slowloris', 1)\n",
    "x['Label'] = x['Label'].replace('DoS slowloris - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('DoS Slowhttptest', 1)\n",
    "x['Label'] = x['Label'].replace('DoS Slowhttptest - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('DoS Hulk', 1)\n",
    "x['Label'] = x['Label'].replace('DoS Hulk - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('DoS GoldenEye', 1)\n",
    "x['Label'] = x['Label'].replace('Heartbleed', 1)\n",
    "x['Label'] = x['Label'].replace('DoS GoldenEye - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('Web Attack - Brute Force', 1)\n",
    "x['Label'] = x['Label'].replace('Web Attack - Brute Force - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('Web Attack - XSS', 1)\n",
    "x['Label'] = x['Label'].replace('Web Attack - XSS - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('Web Attack - Sql Injection', 1)\n",
    "x['Label'] = x['Label'].replace('Infiltration', 1)\n",
    "x['Label'] = x['Label'].replace('Infiltration - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('Bot', 1)\n",
    "x['Label'] = x['Label'].replace('Bot - Attempted', 0)\n",
    "x['Label'] = x['Label'].replace('DDoS', 1)\n",
    "x['Label'] = x['Label'].replace('PortScan', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e247ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "x.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e55d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realiza o One-Hot Encoding\n",
    "#x = pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd011773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separa as labels e os Dados em datasets diferentes\n",
    "data_class = x['Label']\n",
    "data = x.drop(['Label'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596525c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()\n",
    "#transforma dados infinitos em finitos\n",
    "#data = np.nan_to_num(data,posinf=10000000, neginf=10000000)\n",
    "data_class = data_class.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fbfbba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "noTrain = np.count_nonzero(data_class == 0)\n",
    "anTrain = np.count_nonzero(data_class == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c37c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Normais:  1666172 \n",
      "Dados Anômalos:  433849\n"
     ]
    }
   ],
   "source": [
    "print(\"Dados Normais: \", noTrain, \"\\nDados Anômalos: \", anTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d15fc3",
   "metadata": {},
   "source": [
    "# Abordagem Autoencoder-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08807023",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Pré-processando...\n",
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  2\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  3\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  4\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  5\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  6\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  7\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  8\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  9\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n",
      "Fold  10\n",
      "Pré-processando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "KNN...\n",
      "Finalizado.\n",
      "DT...\n",
      "Finalizado.\n",
      "SVM...\n",
      "Finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "activation = \"relu\"\n",
    "neighbors = 11\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "count = 0\n",
    "\n",
    "#Métricas ErroRecons\n",
    "matrix_ErroRecons = np.zeros((num_folds,2,2))\n",
    "accuracy_ErroRecons = np.zeros(num_folds)\n",
    "recall_ErroRecons = np.zeros(num_folds)\n",
    "precision_ErroRecons = np.zeros(num_folds)\n",
    "f1_ErroRecons = np.zeros(num_folds)\n",
    "\n",
    "#Métricas KNN\n",
    "matrix_knn = np.zeros((num_folds,2,2))\n",
    "accuracy_knn = np.zeros(num_folds)\n",
    "recall_knn = np.zeros(num_folds)\n",
    "precision_knn = np.zeros(num_folds)\n",
    "f1_knn = np.zeros(num_folds)\n",
    "\n",
    "#Métricas Decision Tree\n",
    "matrix_dt = np.zeros((num_folds,2,2))\n",
    "accuracy_dt = np.zeros(num_folds)\n",
    "recall_dt = np.zeros(num_folds)\n",
    "precision_dt = np.zeros(num_folds)\n",
    "f1_dt = np.zeros(num_folds)\n",
    "\n",
    "#Métricas SVM\n",
    "matrix_svm = np.zeros((num_folds,2,2))\n",
    "accuracy_svm = np.zeros(num_folds)\n",
    "recall_svm = np.zeros(num_folds)\n",
    "precision_svm = np.zeros(num_folds)\n",
    "f1_svm = np.zeros(num_folds)\n",
    "\n",
    "for train, test in kfold.split(data, data_class):\n",
    "    print(\"Fold \",fold_no)\n",
    "    #####################################################\n",
    "    ####Pré-Processamento\n",
    "    print(\"Pré-processando...\")\n",
    "    \n",
    "    #Separação dos Folds de Treinamento e Teste\n",
    "    dataTrain = data[train]\n",
    "    dataTrain_class = data_class[train]\n",
    "    modelTest = data[test]\n",
    "    modelTest_class = data_class[test]\n",
    "    \n",
    "    #Conta Quantidade de dados\n",
    "    Train = dataTrain.shape[1]\n",
    "    noTrain = np.count_nonzero(dataTrain_class == 0)\n",
    "    anTrain = np.count_nonzero(dataTrain_class == 1)\n",
    "\n",
    "    #Separa dados normais e anômalos\n",
    "    normalTrain = dataTrain[np.where(dataTrain_class == 0)]\n",
    "    anomalyTrain = dataTrain[np.where(dataTrain_class == 1)]\n",
    "    \n",
    "    #Divide dados para treinamento\n",
    "    porcen = 1\n",
    "    j = int(anTrain * porcen)\n",
    "    \n",
    "    #Índices escolhidos aleatoriamente\n",
    "    numbers_knn_normal = np.array(random.sample(range(0, noTrain),j))\n",
    "    numbers_knn_anomaly = np.array(random.sample(range(0,anTrain),j))\n",
    "    numbers_autoencoder_normal = np.array(list(set(np.arange(0, noTrain)) - set(numbers_knn_normal)))\n",
    "    \n",
    "    #Dados KNN\n",
    "    knnTrain_normal = normalTrain[numbers_knn_normal]\n",
    "    knnTrain_anomaly = anomalyTrain[numbers_knn_anomaly]\n",
    "    knnTrain = np.concatenate((knnTrain_normal, knnTrain_anomaly), axis=0)\n",
    "    knnTrain_class = np.concatenate((np.zeros(j), np.ones(j)))\n",
    "    \n",
    "    #Dados Autoencoder\n",
    "    autoencoderTrain = normalTrain[numbers_autoencoder_normal]\n",
    "    autoencoderTrain_class = np.zeros(autoencoderTrain.shape[0])\n",
    "    \n",
    "    #Normalização\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(knnTrain)\n",
    "    autoencoderTrain = scaler.transform(autoencoderTrain)\n",
    "    knnTrain = scaler.transform(knnTrain)\n",
    "    modelTest = scaler.transform(modelTest)\n",
    "    \n",
    "    #####################################################\n",
    "    ####PCA\n",
    "    print(\"PCA\")\n",
    "    #Modela o PCA\n",
    "    var = autoencoderTrain.shape[1]\n",
    "    pca = PCA(n_components=int(var/4))\n",
    "         \n",
    "    #####################################################\n",
    "    ####KNN\n",
    "    ###Treinamento KNN\n",
    "    print(\"KNN...\")\n",
    "    pca.fit(autoencoderTrain)\n",
    "    pca_encoder = pca.transform(knnTrain)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    neigh.fit(pca_encoder, knnTrain_class)\n",
    "    \n",
    "    #Teste do Modelo\n",
    "    pca_encoder = pca.transform(modelTest)\n",
    "    predict_knn = neigh.predict(pca_encoder)\n",
    "    \n",
    "    #Métricas\n",
    "    accuracy_knn[count] = accuracy_score(modelTest_class, predict_knn[:])\n",
    "    recall_knn[count] = recall_score(modelTest_class, predict_knn[:])\n",
    "    precision_knn[count] = precision_score(modelTest_class, predict_knn[:])\n",
    "    f1_knn[count] = f1_score(modelTest_class, predict_knn[:])\n",
    "    matrix_knn[count] = confusion_matrix(modelTest_class, predict_knn[:])\n",
    "    print(\"Finalizado.\")\n",
    "   \n",
    "    #####################################################\n",
    "    ####Decision Tree\n",
    "    ###Treinamento Decision Tree \n",
    "    print(\"DT...\")\n",
    "    pca_encoder = pca.transform(knnTrain)\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "    dt.fit(pca_encoder, knnTrain_class)\n",
    "\n",
    "    #Teste\n",
    "    pca_encoder = pca.transform(modelTest)\n",
    "    predict_dt = dt.predict(pca_encoder)\n",
    "\n",
    "    #Métricas\n",
    "    accuracy_dt[count] = accuracy_score(modelTest_class, predict_dt[:])\n",
    "    recall_dt[count] = recall_score(modelTest_class, predict_dt[:])\n",
    "    precision_dt[count] = precision_score(modelTest_class, predict_dt[:])\n",
    "    f1_dt[count] = f1_score(modelTest_class, predict_dt[:])\n",
    "    matrix_dt[count] = confusion_matrix(modelTest_class, predict_dt[:])\n",
    "    print(\"Finalizado.\")\n",
    "    \n",
    "    #####################################################\n",
    "    ####SVM\n",
    "    #Treinamento SVM\n",
    "    print(\"SVM...\")\n",
    "    pca_encoder = pca.transform(knnTrain)\n",
    "    clf = svm.SVC(kernel='rbf')\n",
    "    clf.fit(pca_encoder, knnTrain_class)\n",
    "    \n",
    "    #Teste\n",
    "    pca_encoder = pca.transform(modelTest)\n",
    "    predict_svm = clf.predict(pca_encoder)\n",
    "    \n",
    "    #Métricas\n",
    "    accuracy_svm[count] = accuracy_score(modelTest_class, predict_svm[:])\n",
    "    recall_svm[count] = recall_score(modelTest_class, predict_svm[:])\n",
    "    precision_svm[count] = precision_score(modelTest_class, predict_svm[:])\n",
    "    f1_svm[count] = f1_score(modelTest_class, predict_svm[:])\n",
    "    matrix_svm[count] = confusion_matrix(modelTest_class, predict_svm[:])\n",
    "    print(\"Finalizado.\")\n",
    "    \n",
    "    Result_GridSearchLimiar = np.array([\"KNN\", \"Acurácia\", accuracy_knn[count], \"\",\n",
    "                                        \"Recall\", recall_knn[count], \"\",\n",
    "                                        \"Precision\", precision_knn[count], \"\",\n",
    "                                        \"F1\", f1_knn[count], \"-----------------\",\"-----------------\",\n",
    "                                    \"Decision Tree\",  \"Acurácia\", accuracy_dt[count],\"\",\n",
    "                                        \"Recall\", recall_dt[count], \"\",\n",
    "                                        \"Precision\", precision_dt[count], \"\",\n",
    "                                        \"F1\", f1_dt[count], \"-----------------\",\"-----------------\",\n",
    "                                    \"SVM\",  \"Acurácia\", accuracy_svm[count],\"\",\n",
    "                                        \"Recall\", recall_svm[count], \"\",\n",
    "                                        \"Precision\", precision_svm[count], \"\",\n",
    "                                        \"F1\", f1_svm[count], \"-----------------\",\"-----------------\",\"-----------------\",\"-----------------\",\n",
    "                                    \"KNN\", matrix_knn[count], \"-----------------\",\"-----------------\",\n",
    "                                    \"Decision Tree\", matrix_dt[count], \"-----------------\",\"-----------------\",\n",
    "                                    \"SVM\", matrix_svm[count]])\n",
    "\n",
    "    np.savetxt('Result_Parcial_CICIDS2017_PCA_Fold'+str(fold_no)+'.txt', Result_GridSearchLimiar, delimiter = ',',fmt='%s')\n",
    "    \n",
    "    count = count + 1\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a03d2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder - KNN:\n",
      " [[1.651884e+05 1.428800e+03]\n",
      " [7.800000e+01 4.330690e+04]] \n",
      "Acurácia:  0.9928248339811196  +/-  0.00040375780336010297 \n",
      "Recall:  0.9982021365318744  +/-  0.0008424984458127966 \n",
      "Precision:  0.9680691193909123  +/-  0.002425010224733569 \n",
      "F1:  0.9829021424457676  +/-  0.0009348031797075339\n",
      "\n",
      "Autoencoder - SVM:\n",
      " [[163214.8   3402.4]\n",
      " [   164.   43220.9]] \n",
      "Acurácia:  0.98301731479867  +/-  0.005415432741519281 \n",
      "Recall:  0.9962198822638122  +/-  0.00043818836998161777 \n",
      "Precision:  0.927567339531206  +/-  0.022563349611918426 \n",
      "F1:  0.9605286972183716  +/-  0.012160833813825518\n",
      "\n",
      "Autoencoder - Decision Tree:\n",
      " [[1.650263e+05 1.590900e+03]\n",
      " [2.130000e+01 4.336360e+04]] \n",
      "Acurácia:  0.9923229339810746  +/-  0.00018285251228485942 \n",
      "Recall:  0.9995090457899056  +/-  0.00011434467619755388 \n",
      "Precision:  0.964611562295788  +/-  0.0008117908793653536 \n",
      "F1:  0.9817501095023016  +/-  0.00042714076211556446\n"
     ]
    }
   ],
   "source": [
    "print(\"Autoencoder - KNN:\\n\", np.mean(matrix_knn, axis=0), \"\\nAcurácia: \", np.mean(accuracy_knn), ' +/- ', np.std(accuracy_knn), \"\\nRecall: \", np.mean(recall_knn), ' +/- ', np.std(recall_knn), \"\\nPrecision: \", np.mean(precision_knn), ' +/- ', np.std(precision_knn), \"\\nF1: \", np.mean(f1_knn), ' +/- ', np.std(f1_knn))\n",
    "\n",
    "print(\"\\nAutoencoder - SVM:\\n\", np.mean(matrix_svm, axis=0), \"\\nAcurácia: \", np.mean(accuracy_svm), ' +/- ', np.std(accuracy_svm), \"\\nRecall: \", np.mean(recall_svm), ' +/- ', np.std(recall_svm), \"\\nPrecision: \", np.mean(precision_svm), ' +/- ', np.std(precision_svm), \"\\nF1: \", np.mean(f1_svm), ' +/- ', np.std(f1_svm))\n",
    "\n",
    "print(\"\\nAutoencoder - Decision Tree:\\n\", np.mean(matrix_dt, axis=0), \"\\nAcurácia: \", np.mean(accuracy_dt), ' +/- ', np.std(accuracy_dt), \"\\nRecall: \", np.mean(recall_dt), ' +/- ', np.std(recall_dt), \"\\nPrecision: \", np.mean(precision_dt), ' +/- ', np.std(precision_dt), \"\\nF1: \", np.mean(f1_dt), ' +/- ', np.std(f1_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c9c802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "Result = np.array([\"KNN\", \"Acurácia\", accuracy_knn, np.mean(accuracy_knn), np.std(accuracy_knn),\"\",\n",
    "                                \"Recall\", recall_knn, np.mean(recall_knn), np.std(recall_knn), \"\",\n",
    "                                \"Precision\", precision_knn, np.mean(precision_knn), np.std(precision_knn), \"\",\n",
    "                                \"F1\", f1_knn, np.mean(f1_knn), np.std(f1_knn), \"-----------------\",\"-----------------\",\n",
    "                  \"Decision Tree\",  \"Acurácia\", accuracy_dt, np.mean(accuracy_dt), np.std(accuracy_dt),\"\",\n",
    "                                \"Recall\", recall_dt, np.mean(recall_dt), np.std(recall_dt), \"\",\n",
    "                                \"Precision\", precision_dt, np.mean(precision_dt), np.std(precision_dt), \"\",\n",
    "                                \"F1\", f1_dt, np.mean(f1_dt), np.std(f1_dt), \"-----------------\",\"-----------------\",\n",
    "                  \"SVM\",  \"Acurácia\", accuracy_svm, np.mean(accuracy_svm), np.std(accuracy_svm),\"\",\n",
    "                                \"Recall\", recall_svm, np.mean(recall_svm), np.std(recall_svm), \"\",\n",
    "                                \"Precision\", precision_svm, np.mean(precision_svm), np.std(precision_svm), \"\",\n",
    "                                \"F1\", f1_svm, np.mean(f1_svm), np.std(f1_svm), \"\",\"\",])\n",
    "\n",
    "np.savetxt('Result_PCA.txt', Result, delimiter = ',',fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d78fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilo/anaconda3/envs/luan/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "Result_Matrix = np.array([\"KNN\", matrix_knn, np.mean(matrix_knn, axis=0), np.std(matrix_knn, axis=0), \"-----------------\",\"-----------------\",\n",
    "                          \"Decision Tree\", matrix_dt, np.mean(matrix_dt, axis=0), np.std(matrix_dt, axis=0), \"-----------------\",\"-----------------\",\n",
    "                          \"SVM\", matrix_svm, np.mean(matrix_svm, axis=0), np.std(matrix_svm, axis=0)])\n",
    "\n",
    "np.savetxt('Result_PCA_Matrix.txt', Result_Matrix, delimiter = ',',fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
