{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9b12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score)\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_som.som import SOM\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f784dda",
   "metadata": {},
   "source": [
    "# Dados NSL-KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe194606",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\luang\\Downloads\\BRACIS\\UNSW_2018_IoT_Botnet_Full5p.csv\")\n",
    "x = data.drop (['category', 'subcategory', 'attack'], axis = 1)\n",
    "y = data ['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934ecb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x.to_numpy()\n",
    "data_class = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d15fc3",
   "metadata": {},
   "source": [
    "# Abordagem Autoencoder-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34590a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CB5D1CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CB5D1CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0095\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0015\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0012\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0011\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0011\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0010\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0010\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0010\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0010\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 22s 2ms/step - loss: 0.0010\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0010\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0010\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0010: 1s - loss: 0.0 - ETA: 1s - loss\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0010\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0010\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0010\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0010\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE729EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE729EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248BE3B3828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248BE3B3828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000248C45E63A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000248C45E63A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 22s 1ms/step - loss: 0.0117\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0042\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0037\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0035\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0035\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0034\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0034\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0034\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0034\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0034\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0034\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0034\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0034\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0034\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0034\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0034\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0034\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0034\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0034\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0034\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0034\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0034\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0033\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0033\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0033\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0033: 0s - lo\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0033\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0033: 0\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0033\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0033\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 16s 1ms/step - loss: 0.0033\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CCB8A3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CCB8A3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CC64BB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CC64BB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247C81CCF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247C81CCF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 24s 2ms/step - loss: 0.0120\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0062\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0055\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0055\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0054\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0054\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 23s 2ms/step - loss: 0.0053\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0053\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0053\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0053\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0053\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0053\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE613A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE613A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE00D798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE00D798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CE2BCCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CE2BCCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 30s 2ms/step - loss: 0.0214\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0103\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0059\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 30s 2ms/step - loss: 0.0056\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 31s 2ms/step - loss: 0.0056\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 29s 2ms/step - loss: 0.0056\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0056\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0055: 0s - loss: 0.0\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 29s 2ms/step - loss: 0.0055\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0055\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0055\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0055\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0055\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 32s 3ms/step - loss: 0.0055\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 29s 2ms/step - loss: 0.0055\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0055\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0055\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0055\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0055\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 32s 3ms/step - loss: 0.0055\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0055\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0055\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0055\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0055\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0055\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0055\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0055\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0055\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 29s 2ms/step - loss: 0.0055\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0055\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0055\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0054\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 29s 2ms/step - loss: 0.0054\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0054\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0054\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 24s 2ms/step - loss: 0.0054\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0054\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0054\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0054\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0054\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0054\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0054\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0054\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - ETA: 0s - loss: 0.005 - 20s 2ms/step - loss: 0.0054\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 22s 2ms/step - loss: 0.0054\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 22s 2ms/step - loss: 0.0054\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0054\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0054\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 30s 2ms/step - loss: 0.0054\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0054\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248827351F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248827351F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE30FAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE30FAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CCB8A5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CCB8A5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 32s 2ms/step - loss: 0.0341\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 31s 2ms/step - loss: 0.0299\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 32s 3ms/step - loss: 0.0296\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 30s 2ms/step - loss: 0.0295\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0295\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 34s 3ms/step - loss: 0.0295\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 32s 2ms/step - loss: 0.0295\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 33s 3ms/step - loss: 0.0295: 0s - loss: 0.029\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0295\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0290\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0230\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 30s 2ms/step - loss: 0.0214\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 30s 2ms/step - loss: 0.0212\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0212: 0s - loss\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 23s 2ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 23s 2ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0212\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248C2694EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248C2694EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE0E2828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE0E2828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CCB97C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CCB97C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0212\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0174\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0161: 0s -\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0161\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0161\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000024882903048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000024882903048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248C456CA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248C456CA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000248828A4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000248828A4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 29s 2ms/step - loss: 0.0237\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0038\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0019: 0s - loss: 0.0\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0016\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0015\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - ETA: 0s - loss: 0.001 - 21s 2ms/step - loss: 0.0015\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0015\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0015\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0015\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0015\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0015\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0015\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0014\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0014\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0014\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0014\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0014\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0014\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0014\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0014\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0014\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0014\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0014\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0014\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0014\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0014\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0014\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248828D2EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248828D2EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE613288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE613288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CE333708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CE333708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0777\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0083\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0059\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 22s 2ms/step - loss: 0.0052\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0047\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0045\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0045\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0044\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0044\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0044\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0044\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0044\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0044\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0044\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0044\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0043\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0043: 1s \n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0043\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 22s 2ms/step - loss: 0.0043\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0043\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0043\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0042\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0043\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0042\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0042\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0042\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0042\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0042\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0042\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0042\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0042\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0042\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CCC14558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CCC14558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000024882FA5828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000024882FA5828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CB255438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CB255438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0236\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0189\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0186\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0186\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 7/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185: 0s \n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0185\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0185\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0185\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0185\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0185\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0185\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0185\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0185\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0184\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0184\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 17s 1ms/step - loss: 0.0184\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 18s 1ms/step - loss: 0.0184\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0184\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0184\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0184: 0\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 23s 2ms/step - loss: 0.0184\n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0184\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0184\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE30FD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE30FD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248827353A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248827353A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CCBB4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000247CCBB4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0201\n",
      "Epoch 2/50\n",
      "12894/12894 [==============================] - 24s 2ms/step - loss: 0.0178\n",
      "Epoch 3/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 5/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 6/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0175\n",
      "Epoch 8/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0175\n",
      "Epoch 9/50\n",
      "12894/12894 [==============================] - 27s 2ms/step - loss: 0.0175\n",
      "Epoch 10/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 12/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 13/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0175: 0s - loss: \n",
      "Epoch 14/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 16/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 17/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 18/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 19/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0175\n",
      "Epoch 20/50\n",
      "12894/12894 [==============================] - 26s 2ms/step - loss: 0.0175\n",
      "Epoch 21/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 22/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 23/50\n",
      "12894/12894 [==============================] - 24s 2ms/step - loss: 0.0175\n",
      "Epoch 24/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 25/50\n",
      "12894/12894 [==============================] - 28s 2ms/step - loss: 0.0175\n",
      "Epoch 26/50\n",
      "12894/12894 [==============================] - 22s 2ms/step - loss: 0.0175\n",
      "Epoch 27/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 28/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175: 0s -\n",
      "Epoch 29/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0175\n",
      "Epoch 30/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 31/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 32/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 33/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 34/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 35/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 36/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 37/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 38/50\n",
      "12894/12894 [==============================] - 19s 1ms/step - loss: 0.0175\n",
      "Epoch 39/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 40/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 41/50\n",
      "12894/12894 [==============================] - 19s 2ms/step - loss: 0.0175\n",
      "Epoch 42/50\n",
      "12894/12894 [==============================] - 23s 2ms/step - loss: 0.0175\n",
      "Epoch 43/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0175\n",
      "Epoch 44/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 45/50\n",
      "12894/12894 [==============================] - 20s 2ms/step - loss: 0.0175\n",
      "Epoch 46/50\n",
      "12894/12894 [==============================] - 22s 2ms/step - loss: 0.0175\n",
      "Epoch 47/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0175\n",
      "Epoch 48/50\n",
      "12894/12894 [==============================] - 25s 2ms/step - loss: 0.0175: 0s - loss: \n",
      "Epoch 49/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0175\n",
      "Epoch 50/50\n",
      "12894/12894 [==============================] - 21s 2ms/step - loss: 0.0175\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248828A4EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000248828A4EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE729438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000247CE729438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "activation = \"relu\"\n",
    "neighbors = 11\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "count = 0\n",
    "\n",
    "#Métricas KNN\n",
    "matrix_knn = np.zeros((num_folds,2,2))\n",
    "accuracy_knn = np.zeros(num_folds)\n",
    "recall_knn = np.zeros(num_folds)\n",
    "precision_knn = np.zeros(num_folds)\n",
    "f1_knn = np.zeros(num_folds)\n",
    "\n",
    "#Métricas Decision Tree\n",
    "matrix_dt = np.zeros((num_folds,2,2))\n",
    "accuracy_dt = np.zeros(num_folds)\n",
    "recall_dt = np.zeros(num_folds)\n",
    "precision_dt = np.zeros(num_folds)\n",
    "f1_dt = np.zeros(num_folds)\n",
    "\n",
    "#Métricas SVM\n",
    "matrix_svm = np.zeros((num_folds,2,2))\n",
    "accuracy_svm = np.zeros(num_folds)\n",
    "recall_svm = np.zeros(num_folds)\n",
    "precision_svm = np.zeros(num_folds)\n",
    "f1_svm = np.zeros(num_folds)\n",
    "\n",
    "for train, test in kfold.split(data, data_class):\n",
    "    \n",
    "    #####################################################\n",
    "    ####Pré-Processamento\n",
    "    \n",
    "    #Separação dos Folds de Treinamento e Teste\n",
    "    dataTrain = data[train]\n",
    "    dataTrain_class = data_class[train]\n",
    "    modelTest = data[test]\n",
    "    modelTest_class = data_class[test]\n",
    "    \n",
    "    #Conta Quantidade de dados\n",
    "    Train = dataTrain.shape[1]\n",
    "    noTrain = np.count_nonzero(dataTrain_class == 0)\n",
    "    anTrain = np.count_nonzero(dataTrain_class == 1)\n",
    "\n",
    "    #Separa dados normais e anômalos\n",
    "    normalTrain = dataTrain[np.where(dataTrain_class == 0)]\n",
    "    anomalyTrain = dataTrain[np.where(dataTrain_class == 1)]\n",
    "    \n",
    "    #Divide dados para treinamento\n",
    "    porcen = 1\n",
    "    j = int(noTrain * porcen)\n",
    "    \n",
    "    #Índices escolhidos aleatoriamente\n",
    "    numbers_knn_normal = np.array(random.sample(range(0, noTrain),j))\n",
    "    numbers_knn_anomaly = np.array(random.sample(range(0,anTrain),j))\n",
    "    numbers_autoencoder_anomaly = np.array(list(set(np.arange(0, anTrain)) - set(numbers_knn_anomaly)))\n",
    "    \n",
    "    #Dados KNN\n",
    "    knnTrain_normal = normalTrain[numbers_knn_normal]\n",
    "    knnTrain_anomaly = anomalyTrain[numbers_knn_anomaly]\n",
    "    knnTrain = np.concatenate((knnTrain_normal, knnTrain_anomaly), axis=0)\n",
    "    knnTrain_class = np.concatenate((np.zeros(j), np.ones(j)))\n",
    "    \n",
    "    #Dados Autoencoder\n",
    "    autoencoderTrain = anomalyTrain[numbers_autoencoder_anomaly]\n",
    "    autoencoderTrain_class = np.ones(autoencoderTrain.shape[0])\n",
    "    \n",
    "    #Normalização\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(knnTrain)\n",
    "    autoencoderTrain = scaler.transform(autoencoderTrain)\n",
    "    knnTrain = scaler.transform(knnTrain)\n",
    "    modelTest = scaler.transform(modelTest)\n",
    "    \n",
    "    #####################################################\n",
    "    ####Autoencoder\n",
    "    #Modela as camadas do Autoencoder\n",
    "    var = autoencoderTrain.shape[1]\n",
    "    input_vector = keras.Input(shape=(var,))\n",
    "    en1 = layers.Dense(int(var/2), activation=activation)(input_vector)\n",
    "    en2 = layers.Dense(int(var/4), activation=activation)(en1)\n",
    "    de1 = layers.Dense(int(var/2), activation=activation)(en2)\n",
    "    de2 = layers.Dense(var, activation=activation)(de1)\n",
    "\n",
    "    #Gera o modelo\n",
    "    autoencoder = keras.Model(input_vector, de2)\n",
    "    \n",
    "    encoder = keras.Model(input_vector, en2)\n",
    "    encoded_input = keras.Input(shape=(int(var/4),))\n",
    "    decoder_layer = autoencoder.layers[-2]\n",
    "    decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "    #Compila o modelo\n",
    "    autoencoder.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
    "\n",
    "    #Treina o modelo\n",
    "    history = autoencoder.fit(autoencoderTrain, autoencoderTrain, epochs = epochs, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    \n",
    "    #####################################################\n",
    "    ####KNN\n",
    "    ###Treinamento KNN\n",
    "    pred_knn = autoencoder.predict(knnTrain)\n",
    "    mse_knn = np.mean(np.power(knnTrain - pred_knn, 2), axis=1)\n",
    "    error_df_knn = pd.DataFrame({'reconstruction_error': mse_knn,\n",
    "                                 'true_class': knnTrain_class})\n",
    "    error_knn = error_df_knn.to_numpy()\n",
    "    encoder_layer = encoder.predict(knnTrain)\n",
    "    error_encoder = np.append(encoder_layer, error_knn[:,0].reshape(-1,1), axis=1)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    neigh.fit(error_encoder, error_knn[:,1])\n",
    "    \n",
    "    #Teste do Modelo\n",
    "    pred_knn = autoencoder.predict(modelTest)\n",
    "    mse_knn = np.mean(np.power(modelTest - pred_knn, 2), axis=1)\n",
    "    error_df_knn = pd.DataFrame({'reconstruction_error': mse_knn,\n",
    "                                'true_class': modelTest_class})\n",
    "    error_knn = error_df_knn.to_numpy()\n",
    "    encoder_layer = encoder.predict(modelTest)\n",
    "    error_encoder = np.append(encoder_layer, error_knn[:,0].reshape(-1,1), axis=1)\n",
    "    predict_knn = neigh.predict(error_encoder)\n",
    "    \n",
    "    #Métricas\n",
    "    accuracy_knn[count] = accuracy_score(error_knn[:,1], predict_knn[:])\n",
    "    recall_knn[count] = recall_score(error_knn[:,1], predict_knn[:])\n",
    "    precision_knn[count] = precision_score(error_knn[:,1], predict_knn[:])\n",
    "    f1_knn[count] = f1_score(error_knn[:,1], predict_knn[:])\n",
    "    matrix_knn[count] = confusion_matrix(error_knn[:,1], predict_knn[:])\n",
    "    \n",
    "      \n",
    "    #####################################################\n",
    "    ####Decision Tree\n",
    "    ###Treinamento Decisition Tree \n",
    "    pred_dt = autoencoder.predict(knnTrain)\n",
    "    mse_dt = np.mean(np.power(knnTrain - pred_dt, 2), axis=1)\n",
    "    error_df_dt = pd.DataFrame({'reconstruction_error': mse_dt,\n",
    "                                     'true_class': knnTrain_class})\n",
    "    error_dt = error_df_dt.to_numpy()\n",
    "    encoder_layer = encoder.predict(knnTrain)\n",
    "    error_encoder = np.append(encoder_layer, error_dt[:,0].reshape(-1,1), axis=1)\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "    dt.fit(error_encoder, error_dt[:,1])\n",
    "\n",
    "    #Teste\n",
    "    pred_dt = autoencoder.predict(modelTest)\n",
    "    mse_dt = np.mean(np.power(modelTest - pred_dt, 2), axis=1)\n",
    "    error_df_dt = pd.DataFrame({'reconstruction_error': mse_dt,\n",
    "                                     'true_class': modelTest_class})\n",
    "    error_dt = error_df_dt.to_numpy()\n",
    "    encoder_layer = encoder.predict(modelTest)\n",
    "    error_encoder = np.append(encoder_layer,error_dt[:,0].reshape(-1,1), axis=1)\n",
    "    predict_dt = dt.predict(error_encoder)\n",
    "\n",
    "    #Métricas\n",
    "    accuracy_dt[count] = accuracy_score(error_dt[:,1], predict_dt[:])\n",
    "    recall_dt[count] = recall_score(error_dt[:,1], predict_dt[:])\n",
    "    precision_dt[count] = precision_score(error_dt[:,1], predict_dt[:])\n",
    "    f1_dt[count] = f1_score(error_dt[:,1], predict_dt[:])\n",
    "    matrix_dt[count] = confusion_matrix(error_dt[:,1], predict_dt[:])\n",
    "       \n",
    "    #####################################################\n",
    "    ####SVM\n",
    "    #Treinamento SVM\n",
    "    pred_svm = autoencoder.predict(knnTrain)\n",
    "    mse_svm = np.mean(np.power(knnTrain - pred_svm, 2), axis=1)\n",
    "    error_df_svm = pd.DataFrame({'reconstruction_error': mse_svm,\n",
    "                                     'true_class': knnTrain_class})\n",
    "    error_svm = error_df_svm.to_numpy()\n",
    "    encoder_layer = encoder.predict(knnTrain)\n",
    "    error_encoder = np.append(encoder_layer, error_svm[:,0].reshape(-1,1), axis=1)\n",
    "    clf = svm.SVC(kernel='rbf')\n",
    "    clf.fit(error_encoder, error_svm[:,1])\n",
    "    \n",
    "    #Teste\n",
    "    pred_svm = autoencoder.predict(modelTest)\n",
    "    mse_svm = np.mean(np.power(modelTest - pred_svm, 2), axis=1)\n",
    "    error_df_svm = pd.DataFrame({'reconstruction_error': mse_svm,\n",
    "                                     'true_class': modelTest_class})\n",
    "    error_svm = error_df_svm.to_numpy()\n",
    "    encoder_layer = encoder.predict(modelTest)\n",
    "    error_encoder = np.append(encoder_layer,error_svm[:,0].reshape(-1,1), axis=1)\n",
    "    predict_svm = clf.predict(error_encoder)\n",
    "    \n",
    "    #Métricas\n",
    "    accuracy_svm[count] = accuracy_score(error_svm[:,1], predict_svm[:])\n",
    "    recall_svm[count] = recall_score(error_svm[:,1], predict_svm[:])\n",
    "    precision_svm[count] = precision_score(error_svm[:,1], predict_svm[:])\n",
    "    f1_svm[count] = f1_score(error_svm[:,1], predict_svm[:])\n",
    "    matrix_svm[count] = confusion_matrix(error_svm[:,1], predict_svm[:])\n",
    "\n",
    "    count = count + 1\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a03d2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder - KNN:\n",
      " [[4.700000e+01 7.000000e-01]\n",
      " [5.213900e+03 3.615906e+05]] \n",
      "Acurácia:  0.9857855585485501  +/-  0.008073759727249661 \n",
      "Recall:  0.9857856140518784  +/-  0.008074699115840469 \n",
      "Precision:  0.9999980629385773  +/-  2.159734509358166e-06 \n",
      "F1:  0.9928242943582062  +/-  0.004103321018109197\n",
      "\n",
      "Autoencoder - SVM:\n",
      " [[4.710000e+01 6.000000e-01]\n",
      " [8.159400e+03 3.586451e+05]] \n",
      "Acurácia:  0.9777567102715332  +/-  0.008027124446846166 \n",
      "Recall:  0.9777554519870251  +/-  0.008027698286780684 \n",
      "Precision:  0.9999983228401528  +/-  1.8618157456467052e-06 \n",
      "F1:  0.9887351491378673  +/-  0.0041054234649395204\n",
      "\n",
      "Autoencoder - Decision Tree:\n",
      " [[4.720000e+01 5.000000e-01]\n",
      " [2.545400e+03 3.642591e+05]] \n",
      "Acurácia:  0.9930601475863796  +/-  0.0030871189532411356 \n",
      "Recall:  0.9930606073324025  +/-  0.003087782448965782 \n",
      "Precision:  0.9999986281573159  +/-  1.8428806504927488e-06 \n",
      "F1:  0.9965151313713371  +/-  0.0015554685626742743\n"
     ]
    }
   ],
   "source": [
    "print(\"Autoencoder - KNN:\\n\", np.mean(matrix_knn, axis=0), \"\\nAcurácia: \", np.mean(accuracy_knn), ' +/- ', np.std(accuracy_knn), \"\\nRecall: \", np.mean(recall_knn), ' +/- ', np.std(recall_knn), \"\\nPrecision: \", np.mean(precision_knn), ' +/- ', np.std(precision_knn), \"\\nF1: \", np.mean(f1_knn), ' +/- ', np.std(f1_knn))\n",
    "\n",
    "print(\"\\nAutoencoder - SVM:\\n\", np.mean(matrix_svm, axis=0), \"\\nAcurácia: \", np.mean(accuracy_svm), ' +/- ', np.std(accuracy_svm), \"\\nRecall: \", np.mean(recall_svm), ' +/- ', np.std(recall_svm), \"\\nPrecision: \", np.mean(precision_svm), ' +/- ', np.std(precision_svm), \"\\nF1: \", np.mean(f1_svm), ' +/- ', np.std(f1_svm))\n",
    "\n",
    "print(\"\\nAutoencoder - Decision Tree:\\n\", np.mean(matrix_dt, axis=0), \"\\nAcurácia: \", np.mean(accuracy_dt), ' +/- ', np.std(accuracy_dt), \"\\nRecall: \", np.mean(recall_dt), ' +/- ', np.std(recall_dt), \"\\nPrecision: \", np.mean(precision_dt), ' +/- ', np.std(precision_dt), \"\\nF1: \", np.mean(f1_dt), ' +/- ', np.std(f1_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8521f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luang\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "Result = np.array([\"KNN\", \"Acurácia\", accuracy_knn, np.mean(accuracy_knn), np.std(accuracy_knn),\"\",\n",
    "                                \"Recall\", recall_knn, np.mean(recall_knn), np.std(recall_knn), \"\",\n",
    "                                \"Precision\", precision_knn, np.mean(precision_knn), np.std(precision_knn), \"\",\n",
    "                                \"F1\", f1_knn, np.mean(f1_knn), np.std(f1_knn), \"-----------------\",\"-----------------\",\n",
    "                  \"Decision Tree\",  \"Acurácia\", accuracy_dt, np.mean(accuracy_dt), np.std(accuracy_dt),\"\",\n",
    "                                \"Recall\", recall_dt, np.mean(recall_dt), np.std(recall_dt), \"\",\n",
    "                                \"Precision\", precision_dt, np.mean(precision_dt), np.std(precision_dt), \"\",\n",
    "                                \"F1\", f1_dt, np.mean(f1_dt), np.std(f1_dt), \"-----------------\",\"-----------------\",\n",
    "                  \"SVM\",  \"Acurácia\", accuracy_svm, np.mean(accuracy_svm), np.std(accuracy_svm),\"\",\n",
    "                                \"Recall\", recall_svm, np.mean(recall_svm), np.std(recall_svm), \"\",\n",
    "                                \"Precision\", precision_svm, np.mean(precision_svm), np.std(precision_svm), \"\",\n",
    "                                \"F1\", f1_svm, np.mean(f1_svm), np.std(f1_svm), \"\",\"\",])\n",
    "\n",
    "np.savetxt('Result_Error+IL_IoT.txt', Result, delimiter = ',',fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcb1abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luang\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "Result_Matrix = np.array([\"KNN\", matrix_knn, np.mean(matrix_knn, axis=0), np.std(matrix_knn, axis=0), \"-----------------\",\"-----------------\",\n",
    "                          \"Decision Tree\", matrix_dt, np.mean(matrix_dt, axis=0), np.std(matrix_dt, axis=0), \"-----------------\",\"-----------------\",\n",
    "                          \"SVM\", matrix_svm, np.mean(matrix_svm, axis=0), np.std(matrix_svm, axis=0)])\n",
    "\n",
    "np.savetxt('Result_Error+IL_Matrix_IoT.txt', Result_Matrix, delimiter = ',',fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
